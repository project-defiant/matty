{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA GeForce RTX 4070 is available\n",
      "(8, 9)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available:\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()} is available\")\n",
    "    print(f\"{torch.cuda.get_device_capability()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic information about the tensors\n",
    "Tensor can be either:\n",
    "- scalar \n",
    "- vector\n",
    "- matrix\n",
    "- tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = torch.tensor(7)\n",
    "vector = torch.tensor([1,7])\n",
    "matrix = torch.tensor([[1,-1], [1,-1]])\n",
    "tensor = torch.tensor([[[1,-1],[1,-1], [1,-1], [1,-1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar: tensor(7)\n",
      "f.size()=torch.Size([])\n",
      "f.shape=torch.Size([])\n",
      "f.dim()=0\n",
      "vector: tensor([1, 7])\n",
      "f.size()=torch.Size([2])\n",
      "f.shape=torch.Size([2])\n",
      "f.dim()=1\n",
      "matrix: tensor([[ 1, -1],\n",
      "        [ 1, -1]])\n",
      "f.size()=torch.Size([2, 2])\n",
      "f.shape=torch.Size([2, 2])\n",
      "f.dim()=2\n",
      "tensor: tensor([[[ 1, -1],\n",
      "         [ 1, -1],\n",
      "         [ 1, -1],\n",
      "         [ 1, -1]]])\n",
      "f.size()=torch.Size([1, 4, 2])\n",
      "f.shape=torch.Size([1, 4, 2])\n",
      "f.dim()=3\n"
     ]
    }
   ],
   "source": [
    "for k,f in {\"scalar\": scalar,\"vector\": vector,\"matrix\":matrix,\"tensor\": tensor}.items():\n",
    "    print(f\"{k}:\", f)\n",
    "    print(f\"{f.size()=}\")\n",
    "    print(f\"{f.shape=}\")\n",
    "    print(f\"{f.dim()=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information from the tensors\n",
    "\n",
    "1. get dtype - use `tensor.dtype`\n",
    "2. get shape of a tensor - use `tensor.shape`\n",
    "3. get device - use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9454, 0.7454, 0.6557, 0.2135],\n",
      "        [0.4512, 0.7742, 0.5876, 0.6407],\n",
      "        [0.4083, 0.8609, 0.3850, 0.2991]], device='cuda:0')\n",
      "torch.float32\n",
      "torch.Size([3, 4])\n",
      "cuda:0\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(size=(3, 4), dtype=torch.float32, device=\"cuda\")\n",
    "print(some_tensor)\n",
    "print(some_tensor.dtype) # torch.float32 by default\n",
    "print(some_tensor.shape) # torch.Size[3,4]\n",
    "print(some_tensor.device) # cuda(0) by default cpu\n",
    "\n",
    "print(some_tensor.size())  # semantically equivalent to `some_tensor.shape`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above values accomodate almost all issues with testors:\n",
    "* tensors not in the right type\n",
    "* tesnors not in the right shape\n",
    "* tensors not in the same device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors\n",
    "\n",
    "Tensor operations include\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication\n",
    "* Division\n",
    "* Matrix multiplication (MatMul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([10, 20, 30])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor + 10)\n",
    "print(tensor * 10)\n",
    "print(tensor - 10)\n",
    "print(tensor / 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the context above we can see, that the tensors are immutable within these operations.\n",
    "There are also `torch` operations that do the same under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([10, 20, 30])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([0.1000, 0.2000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(tensor, 10))\n",
    "print(torch.mul(tensor, 10))\n",
    "print(torch.sub(tensor, 10))\n",
    "print(torch.div(tensor, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication\n",
    "\n",
    "1. Element-wise multiplication\n",
    "2. matrix multiplication (dot product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]]) * tensor([[1., 2.],\n",
      "        [3., 4.]]) = tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]]) @ tensor([[1., 2.],\n",
      "        [3., 4.]]) = tensor([[ 7., 10.],\n",
      "        [15., 22.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.Tensor([[1,2], [3,4]])\n",
    "\n",
    "print(f\"{tensor} * {tensor} = {tensor * tensor}\")\n",
    "print(f\"{tensor} @ {tensor} = {tensor.matmul(tensor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product must follow the condition:\n",
    "* The inner dimentions must match!\n",
    "* The resulting matrix has the shape of outer dimentions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 3.],\n",
      "        [2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)\n",
    "print(tensor.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tesnor aggregations\n",
    "* min\n",
    "* max\n",
    "* mean \n",
    "* sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor(1.)\n",
      "tensor(4.)\n",
      "tensor(10.)\n",
      "tensor(3)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(tensor))\n",
    "print(torch.min(tensor))\n",
    "print(torch.max(tensor))\n",
    "print(torch.sum(tensor))\n",
    "print(tensor.argmax())\n",
    "print(tensor.argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "\n",
      "Reshaping size 9 to 3x3\n",
      "Reshaped tensor: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1., 10.)\n",
    "print(f\"Original tensor: {x}\")\n",
    "# x_reshaped = x.reshape(1,7) # will throw error that tensor of size 9 can not be reshaped\n",
    "x_reshaped = x.reshape(3,3)\n",
    "print(\"\\nReshaping size 9 to 3x3\")\n",
    "print(f\"Reshaped tensor: {x_reshaped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Original tensor view tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "\n",
      "Reshaping the view\n",
      "Original tensor: tensor([10.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])\n",
      "Original tensor view tensor([[10.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(1,9)\n",
    "print(f\"Original tensor: {x}\")\n",
    "print(f\"Original tensor view {z}\")\n",
    "\n",
    "# Now we reshape the tensor z\n",
    "print(\"\\nReshaping the view\")\n",
    "x[0] = 10\n",
    "print(f\"Original tensor: {x}\")\n",
    "print(f\"Original tensor view {z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dim: 1\n",
      "Stacked 4 x tensors = tensor([[10., 10., 10., 10.],\n",
      "        [ 2.,  2.,  2.,  2.],\n",
      "        [ 3.,  3.,  3.,  3.],\n",
      "        [ 4.,  4.,  4.,  4.],\n",
      "        [ 5.,  5.,  5.,  5.],\n",
      "        [ 6.,  6.,  6.,  6.],\n",
      "        [ 7.,  7.,  7.,  7.],\n",
      "        [ 8.,  8.,  8.,  8.],\n",
      "        [ 9.,  9.,  9.,  9.]])\n",
      "New dim: 2\n"
     ]
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim = 1)\n",
    "print(f\"Original dim: {x.dim()}\")\n",
    "print(f\"Stacked 4 x tensors = {x_stacked}\")\n",
    "print(f\"New dim: {x_stacked.dim()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New tensor tensor([[0.4981, 0.5100],\n",
      "        [0.4335, 0.6107]])\n",
      "tensor([[[0.4981, 0.4981],\n",
      "         [0.5100, 0.5100]],\n",
      "\n",
      "        [[0.4335, 0.4335],\n",
      "         [0.6107, 0.6107]]])\n"
     ]
    }
   ],
   "source": [
    "# as we can see the dim can be either 0 -> rows or 1 -> cols\n",
    "# Lets see the dim 2 tensor\n",
    "x2 = torch.rand(size=(2,2))\n",
    "print(f\"New tensor {x2}\")\n",
    "\n",
    "x2_stacked = torch.stack([x2,x2], dim=2)\n",
    "print(x2_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.,  2.,  3.,  4.,  5.,\n",
      "         6.,  7.,  8.,  9.])\n",
      "tensor([[10.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.],\n",
      "        [10.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "# hstack and vstack\n",
    "print(torch.hstack([x,x]))\n",
    "print(torch.vstack([x,x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For squeeze we need a tensor with any shape element == 1, they will be dropped\n",
      "Input tensor: tensor([[[[[0., 0.]],\n",
      "\n",
      "          [[0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0.]],\n",
      "\n",
      "          [[0., 0.]]]]])\n",
      "Shape: torch.Size([2, 1, 2, 1, 2])\n",
      "\n",
      "Squeezed tensor tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "Shape: torch.Size([2, 2, 2])\n",
      "\n",
      "Unsqueezed tensor tensor([[[[0., 0.]],\n",
      "\n",
      "         [[0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0.]],\n",
      "\n",
      "         [[0., 0.]]]])\n",
      "Shape: torch.Size([2, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# squeeze and unsqueeze\n",
    "x3 = torch.zeros(2,1,2,1,2)\n",
    "print(f\"For squeeze we need a tensor with any shape element == 1, they will be dropped\\nInput tensor: {x3}\\nShape: {x3.shape}\")\n",
    "print(f\"\\nSqueezed tensor {torch.squeeze(x3)}\\nShape: {torch.squeeze(x3).shape}\")\n",
    "print(f\"\\nUnsqueezed tensor {torch.unsqueeze(torch.squeeze(x3), dim=2)}\\nShape: {torch.unsqueeze(torch.squeeze(x3), dim=2).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "tensor([[[-0.1620,  0.5361,  1.1587, -0.2928, -1.9598],\n",
      "         [ 2.0286, -1.2822,  0.2926,  1.5987,  0.7542],\n",
      "         [ 0.7225,  1.7440,  0.6000, -0.4700,  0.4795]],\n",
      "\n",
      "        [[-1.3284, -0.1983,  0.4187,  0.1251, -1.0933],\n",
      "         [ 0.8309, -0.0958, -1.7125, -0.3283, -1.2900],\n",
      "         [-0.8559,  0.2181, -0.9814,  0.5835, -0.1846]]])\n",
      "torch.Size([5, 2, 3])\n",
      "tensor([[[-0.1620,  2.0286,  0.7225],\n",
      "         [-1.3284,  0.8309, -0.8559]],\n",
      "\n",
      "        [[ 0.5361, -1.2822,  1.7440],\n",
      "         [-0.1983, -0.0958,  0.2181]],\n",
      "\n",
      "        [[ 1.1587,  0.2926,  0.6000],\n",
      "         [ 0.4187, -1.7125, -0.9814]],\n",
      "\n",
      "        [[-0.2928,  1.5987, -0.4700],\n",
      "         [ 0.1251, -0.3283,  0.5835]],\n",
      "\n",
      "        [[-1.9598,  0.7542,  0.4795],\n",
      "         [-1.0933, -1.2900, -0.1846]]])\n"
     ]
    }
   ],
   "source": [
    "## Permute swaps order of the dimentions\n",
    "x4 = torch.randn(2,3,5)\n",
    "print(x4.size())\n",
    "print(x4)\n",
    "print(torch.permute(x4, (2,0,1)).shape)\n",
    "print(torch.permute(x4, (2,0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting data from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "Shape: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x5 = torch.arange(1, 10).reshape(1,3,3)\n",
    "print(f\"Original tensor {x5}\\nShape: {x5.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([1, 2, 3])\n",
      "tensor(1)\n",
      "tensor(9)\n",
      "tensor([3, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "print(x5[0])\n",
    "print(x5[0,0])\n",
    "print(x5[0,0,0])\n",
    "print(x5[0][-1][-1])\n",
    "print(x5[0, :, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array: [1. 8.]\n",
      "Tensor from array: tensor([1., 8.], dtype=torch.float64)\n",
      "tensor([2., 8.], dtype=torch.float64)\n",
      "[2. 8.]\n",
      "Array from tensor: [2. 8.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# From numpy to tensor\n",
    "array = np.array([1.0, 8.0])\n",
    "print(f\"Numpy array: {array}\")\n",
    "tensor = torch.from_numpy(array)\n",
    "print(f\"Tensor from array: {tensor}\")\n",
    "# NOTE: Default numpy dtype is float64, this will be kept even though torch default is float32\n",
    "# Changing the array in place also changes tensor (this means that the torch just links to numpy array heap space)\n",
    "array[0] = 2.00\n",
    "print(tensor)\n",
    "print(array)\n",
    "\n",
    "# From tensor to numpy\n",
    "array2 = tensor.numpy()\n",
    "print(f\"Array from tensor: {array2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "\n",
    "Trying to take the random out of random !\n",
    "\n",
    "` Start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again...`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 100\n",
    "\n",
    "# Will make 2 different tensorsb\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "print(random_tensor_C == random_tensor_D)\n",
    "\n",
    "\n",
    "# With random seed reset will make the same tensor!\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "print(random_tensor_C == random_tensor_D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  9 18:00:07 2024       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4070        Off |   00000000:07:00.0  On |                  N/A |\r\n",
      "|  0%   27C    P2             27W /  200W |     582MiB /  12282MiB |      4%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    0   N/A  N/A      2422      G   /usr/lib/xorg/Xorg                            162MiB |\r\n",
      "|    0   N/A  N/A      2583      G   /usr/bin/gnome-shell                           80MiB |\r\n",
      "|    0   N/A  N/A      3529      G   ...yOnDemand --variations-seed-version         48MiB |\r\n",
      "|    0   N/A  N/A      6199      G   ...erProcess --variations-seed-version         98MiB |\r\n",
      "|    0   N/A  N/A      7217      C   ...ojects/pytorch-tut/.venv/bin/python        178MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2,3]], device=\"cuda\")\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "CPU times: user 80.3 ms, sys: 5.57 ms, total: 85.9 ms\n",
      "Wall time: 25.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t1 = torch.rand([1000, 1000], device=\"cpu\")\n",
    "t2 = torch.rand([1000, 1000], device=\"cpu\") \n",
    "t3 = t1 @ t2\n",
    "print(t3.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "CPU times: user 67.2 ms, sys: 41.7 ms, total: 109 ms\n",
      "Wall time: 84.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t1 = torch.rand([1000, 1000], device=\"cuda\")\n",
    "t2 = torch.rand([1000, 1000], device=\"cuda\") \n",
    "t3 = t1 @ t2\n",
    "print(t3.dim())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
